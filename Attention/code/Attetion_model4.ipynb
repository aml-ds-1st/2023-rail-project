{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 10 # 원하는 sequence_length 설정\n",
    "batch_size = 36 # 원하는 batch_size 설정 >> 6시간 기준\n",
    "hidden_size = 16 # 원하는 hidden_size 설정\n",
    "input_size = 11 # 사용하는 feature의 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AML2\\AppData\\Local\\Temp\\ipykernel_7016\\66687605.py:30: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  return torch.tensor(x_seq, dtype=torch.float32), torch.tensor(y_seq, dtype=torch.float32).view(-1,1)\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv('../../data/Rail_data.csv')\n",
    "df = pd.read_csv('../../data/Rail_data.csv')\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# scaled_col = ['air_temp','TSI','azimuth','altitude','solar_rad','High_solar_rad', 'casi', 'humidity', 'rain', 'wind_speed','wind_direction','rail_direction']\n",
    "# df[scaled_col]= scaler.fit_transform(df[scaled_col])\n",
    "\n",
    "# scaler1 = MinMaxScaler()\n",
    "# df['rail_temp'] = scaler1.fit_transform(df['rail_temp'].values.reshape(-1,1))\n",
    "\n",
    "df = df.astype({'solar_rad': 'float64'})\n",
    "df = df.astype({'High_solar_rad': 'float64'})\n",
    "df = df.astype({'casi': 'float64'})\n",
    "df = df.astype({'humidity': 'float64'})\n",
    "df = df.astype({'wind_speed': 'float64'})\n",
    "df = df.drop(['rail_direction'], axis=1)\n",
    "# int type >> float type\n",
    "\n",
    "X = df.iloc[:,:11].values\n",
    "y = df.iloc[:,11].values\n",
    "\n",
    "\n",
    "def sequence_data(X,y, sequence_size): # 원하는 sequence에 따라 데이터 분리\n",
    "    x_seq = []\n",
    "    y_seq = []\n",
    "    for idx in range(len(X) - sequence_size): #len(X)가 7000이고 seq_size가 5라면?\n",
    "        x_seq.append(X[idx:idx + sequence_size]) # sequence_lengh개씩 특성들을 모두 묶음 >> shape: 5, 11\n",
    "        y_seq.append(y[idx + sequence_size])     # x에 따른 온도들을 묶음 >> shape: 5, 1\n",
    "        \n",
    "    return torch.tensor(x_seq, dtype=torch.float32), torch.tensor(y_seq, dtype=torch.float32).view(-1,1)\n",
    "\n",
    "\n",
    "X_seq, y_seq = sequence_data(X, y, sequence_length) # 원하는 sequence_length에 따라 데이터 묶기\n",
    "\n",
    "X_train, X_test = X_seq[:int(len(X_seq)*0.7)], X_seq[int(len(X_seq)*0.7):]\n",
    "y_train, y_test = y_seq[:int(len(y_seq)*0.7)], y_seq[int(len(y_seq)*0.7):]\n",
    "\n",
    "train_DS = TensorDataset(X_train, y_train)\n",
    "test_DS = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_DL = DataLoader(train_DS, batch_size = batch_size*2)\n",
    "test_DL = DataLoader(test_DS, batch_size = batch_size*2)\n",
    "# batch_size에 따라 데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([72, 10, 11])\n",
      "torch.Size([36, 1])\n",
      "torch.Size([72, 10, 11])\n",
      "torch.Size([72, 1])\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_DL))\n",
    "seq, target = data[0], data[1]\n",
    "target = target[int(len(target)*0.5):] \n",
    "\n",
    "print(seq.shape)\n",
    "print(target.shape)\n",
    "print(data[0].shape)\n",
    "print(data[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, device):\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        \n",
    "        self.LSTM = nn.LSTM(input_size, hidden_size, batch_first=True).to(self.device)\n",
    "        # hidden_size를 가진 hidden_state 출력\n",
    "        \n",
    "    def forward(self, x): \n",
    "        _, enc_hid = self.LSTM(x) \n",
    "        # hidden: 1, 36, 16(1, batch, hidden_size) >> (1, 16)짜리가 36개(각각의 state마다의 hidden_state를 포함)\n",
    "        \n",
    "        return enc_hid\n",
    "    \n",
    "        \n",
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(self, hidden_size, device):\n",
    "        super(LSTMDecoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        \n",
    "        self.LSTM = nn.LSTM(hidden_size, hidden_size, batch_first=True).to(self.device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        _, dec_hid = self.LSTM(x)\n",
    "     \n",
    "        return dec_hid\n",
    "        \n",
    "        # prediction을 다시 input으로 decoder 투입\n",
    "        # prediction이 input으로 들어가서 다시 attention한 후에 next prediction을 출력\n",
    "        # attention 후에 decoder 내부에서 기존의 attention처럼 진행하는 것이 가능한가?\n",
    "        # prediction의 hidden_state를 이용해서 next prediction을 하는 것이 예측에 도움을 줄 수 있는가? \n",
    "        \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, sequence_length, device):\n",
    "        super(Attention, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.device = device \n",
    "        self.encoder = LSTMEncoder(input_size, hidden_size, device).to(self.device)\n",
    "        self.decoder = LSTMDecoder(hidden_size, device).to(self.device)\n",
    "        \n",
    "        self.to_query = nn.Linear(hidden_size, hidden_size).to(self.device)\n",
    "        self.to_key = nn.Linear(hidden_size, hidden_size).to(self.device)\n",
    "        self.to_value = nn.Linear(hidden_size, hidden_size).to(self.device)\n",
    "        \n",
    "        \n",
    "        self.LSTM = nn.LSTM(hidden_size, hidden_size, batch_first = True).to(self.device)\n",
    "        self.fc = nn.Linear(input_size, hidden_size)\n",
    "        self.fc0 = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        # hidden * 2 >> Concatenated hidden, hidden >> original hidden\n",
    "        self.fc1 = nn.Linear(sequence_length * hidden_size, 1)    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # enc_x, dec_x로 나누기\n",
    "        enc_x, dec_x = x[:int(len(x)*0.5)], x[int(len(x)*0.5):] \n",
    "        \n",
    "        _, enc_hid = self.encoder(enc_x)\n",
    "        \n",
    "        \n",
    "        enc_hid = torch.tensor(enc_hid)\n",
    "        \n",
    "        \n",
    "        dec_input = self.fc(dec_x)\n",
    "        # 36, 10, 16\n",
    "        \n",
    "        for _ in range(sequence_length):\n",
    "            \n",
    "            _, dec_hid = self.decoder(dec_input)\n",
    "            \n",
    "            query = self.to_query(dec_hid) # 1, batch, hidden_size   \n",
    "            key = self.to_key(enc_hid)  # 1, batch, hidden_size\n",
    "            value = self.to_value(enc_hid) # 1, batch, hidden_size\n",
    "            \n",
    "            query = query.permute(1, 2, 0).contiguous() # batch, hidden_size, 1\n",
    "            key = key.permute(1, 0, 2).contiguous() # batch, 1, hidden_size\n",
    "            value = value.permute(1, 2, 0).contiguous() # batch, hidden_size, 1\n",
    "            \n",
    "            \n",
    "            attention_score = query @ key # batch, hidden_size, 1 @ batch, 1, hidden_size\n",
    "            attention_score = attention_score.softmax(dim = -1) # batch, hidden_size, hidden_size\n",
    "\n",
    "            attention_value = attention_score @ value # batch, hidden_size, 1\n",
    "            # hidden_size, hidden_size @ hidden_size, 1 >> hidden_size,1\n",
    "            attention_value = attention_value.permute(2, 0, 1).contiguous() # 1, batch, hidden_size\n",
    "            \n",
    "            new_hidden = torch.tanh(self.fc0(torch.cat((attention_value, dec_hid),dim=2))) # 1, batch, hidden_size\n",
    "            cell_state = torch.zeros_like(new_hidden)\n",
    "            \n",
    "            out, _  = self.LSTM(dec_input, (new_hidden, cell_state)) # batch, sequence_length, hidden_size\n",
    "            out = out.reshape(out.shape[0], -1) # batch, sequence_length * hidden_size\n",
    "            out = self.fc1(out) # batch, 1\n",
    "            \n",
    "            # dec_input = out.unsqueeze(1) # batch, 1, 1\n",
    "            # dec_input = dec_input.repeat(1, hidden_size, 1) # batch, hidden_size, 1\n",
    "            # dec_input = dec_input.permute(0, 2, 1).contiguous()\n",
    "            # dec_input = dec_input.repeat(1, sequence_length, 1) # batch, sequence_length, hidden_size\n",
    "            \n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #gpu 활성화 확인\n",
    "# model = Attention(input_size, hidden_size, sequence_length, device).to(device)\n",
    "\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(model.parameters(),lr=1e-4)\n",
    "\n",
    "# loss_graph = []\n",
    "# n = len(train_DL)\n",
    "\n",
    "# for epoch in range(100):\n",
    "#     running_loss = 0\n",
    "#     for data in train_DL:\n",
    "#         seq, target = data[0].to(device), data[1].to(device)\n",
    "#         target = target[int(len(target)*0.5):] \n",
    "        \n",
    "        \n",
    "#         out = model(seq)\n",
    "#         loss = criterion(out, target)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         running_loss += loss.item()\n",
    "#     loss_graph.append(running_loss/n)\n",
    "#     if epoch % 10 == 0:\n",
    "#         print(\"[epoch: %d] loss : %.4f\" %(epoch,running_loss/n))\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #gpu 활성화 확인\n",
    "# model = Attention(input_size, hidden_size, sequence_length, device).to(device)\n",
    "\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(model.parameters(),lr=1e-4)\n",
    "\n",
    "# loss_graph = []\n",
    "# n = len(train_DL)\n",
    "\n",
    "# for epoch in range(200):\n",
    "#     running_loss = 0\n",
    "#     for data in train_DL:\n",
    "#         seq, target = data[0].to(device), data[1].to(device)\n",
    "#         target = target[int(len(target)*0.5):] \n",
    "        \n",
    "        \n",
    "#         out = model(seq)\n",
    "#         loss = criterion(out, target)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         running_loss += loss.item()\n",
    "#     loss_graph.append(running_loss/n)\n",
    "#     if epoch % 10 == 0:\n",
    "#         print(\"[epoch: %d] loss : %.4f\" %(epoch,running_loss/n))\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AML2\\AppData\\Local\\Temp\\ipykernel_7016\\93015793.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  enc_hid = torch.tensor(enc_hid)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0] loss : 521.5845\n",
      "[epoch: 50] loss : 49.5351\n",
      "[epoch: 100] loss : 35.5110\n",
      "[epoch: 150] loss : 25.6789\n",
      "[epoch: 200] loss : 18.9078\n",
      "[epoch: 250] loss : 14.7053\n",
      "[epoch: 300] loss : 12.3734\n",
      "[epoch: 350] loss : 12.8232\n",
      "[epoch: 400] loss : 9.3635\n",
      "[epoch: 450] loss : 9.4031\n",
      "[epoch: 500] loss : 8.2571\n",
      "[epoch: 550] loss : 8.6588\n",
      "[epoch: 600] loss : 8.6052\n",
      "[epoch: 650] loss : 8.2544\n",
      "[epoch: 700] loss : 6.7696\n",
      "[epoch: 750] loss : 6.0949\n",
      "[epoch: 800] loss : 6.1649\n",
      "[epoch: 850] loss : 4.8717\n",
      "[epoch: 900] loss : 4.7959\n",
      "[epoch: 950] loss : 4.8786\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #gpu 활성화 확인\n",
    "model = Attention(input_size, hidden_size, sequence_length, device).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-4)\n",
    "\n",
    "loss_graph = []\n",
    "n = len(train_DL)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    running_loss = 0\n",
    "    for data in train_DL:\n",
    "        seq, target = data[0].to(device), data[1].to(device)\n",
    "        target = target[int(len(target)*0.5):] \n",
    "        \n",
    "        \n",
    "        out = model(seq)\n",
    "        loss = criterion(out, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    loss_graph.append(running_loss/n)\n",
    "    if epoch % 50 == 0:\n",
    "        print(\"[epoch: %d] loss : %.4f\" %(epoch,running_loss/n))\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #gpu 활성화 확인\n",
    "model = Attention(input_size, hidden_size, sequence_length, device).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-4)\n",
    "\n",
    "loss_graph = []\n",
    "n = len(train_DL)\n",
    "\n",
    "for epoch in range(2000):\n",
    "    running_loss = 0\n",
    "    for data in train_DL:\n",
    "        seq, target = data[0].to(device), data[1].to(device)\n",
    "        target = target[int(len(target)*0.5):] \n",
    "        \n",
    "        \n",
    "        out = model(seq)\n",
    "        loss = criterion(out, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    loss_graph.append(running_loss/n)\n",
    "    if epoch % 50 == 0:\n",
    "        print(\"[epoch: %d] loss : %.4f\" %(epoch,running_loss/n))\n",
    "       \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
