{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 10 # 원하는 sequence_length 설정\n",
    "batch_size = 36 # 원하는 batch_size 설정 >> 6시간 기준\n",
    "hidden_size = 16 # 원하는 hidden_size 설정\n",
    "input_size = 11 # 사용하는 feature의 수\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../../data/Rail_data.csv')\n",
    "df = pd.read_csv('../../data/Rail_data.csv')\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# scaled_col = ['air_temp','TSI','azimuth','altitude','solar_rad','High_solar_rad', 'casi', 'humidity', 'rain', 'wind_speed','wind_direction','rail_direction']\n",
    "# df[scaled_col]= scaler.fit_transform(df[scaled_col])\n",
    "\n",
    "# scaler1 = MinMaxScaler()\n",
    "# df['rail_temp'] = scaler1.fit_transform(df['rail_temp'].values.reshape(-1,1))\n",
    "\n",
    "df = df.astype({'solar_rad': 'float64'})\n",
    "df = df.astype({'High_solar_rad': 'float64'})\n",
    "df = df.astype({'casi': 'float64'})\n",
    "df = df.astype({'humidity': 'float64'})\n",
    "df = df.astype({'wind_speed': 'float64'})\n",
    "df = df.drop(['rail_direction'], axis=1)\n",
    "# int type >> float type\n",
    "\n",
    "X = df.iloc[:,:11].values\n",
    "y = df.iloc[:,11].values\n",
    "\n",
    "\n",
    "def sequence_data(X,y, sequence_size): # 원하는 sequence에 따라 데이터 분리\n",
    "    x_seq = []\n",
    "    y_seq = []\n",
    "    for idx in range(len(X) - sequence_size): #len(X)가 7000이고 seq_size가 5라면?\n",
    "        x_seq.append(X[idx:idx + sequence_size]) # sequence_lengh개씩 특성들을 모두 묶음 >> shape: 5, 11\n",
    "        y_seq.append(y[idx + sequence_size])     # x에 따른 온도들을 묶음 >> shape: 5, 1\n",
    "        \n",
    "    return torch.tensor(x_seq, dtype=torch.float32), torch.tensor(y_seq, dtype=torch.float32).view(-1,1)\n",
    "\n",
    "\n",
    "X_seq, y_seq = sequence_data(X, y, sequence_length) # 원하는 sequence_length에 따라 데이터 묶기\n",
    "\n",
    "X_train, X_test = X_seq[:int(len(X_seq)*0.7)], X_seq[int(len(X_seq)*0.7):]\n",
    "y_train, y_test = y_seq[:int(len(y_seq)*0.7)], y_seq[int(len(y_seq)*0.7):]\n",
    "\n",
    "train_DS = TensorDataset(X_train, y_train)\n",
    "test_DS = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_DL = DataLoader(train_DS, batch_size = batch_size*2)\n",
    "test_DL = DataLoader(test_DS, batch_size = batch_size*2)\n",
    "# batch_size에 따라 데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([72, 10, 11])\n",
      "torch.Size([72, 1])\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_DL))\n",
    "print(data[0].shape)\n",
    "print(data[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, device):\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        \n",
    "        self.LSTM = nn.LSTM(input_size, hidden_size, batch_first=True).to(self.device)\n",
    "        # hidden_size를 가진 hidden_state 출력\n",
    "        \n",
    "    def forward(self, x): \n",
    "        _, enc_hid = self.LSTM(x) \n",
    "        # hidden: 1, 36, 16(1, batch, hidden_size) >> (1, 16)짜리가 36개(각각의 state마다의 hidden_state를 포함)\n",
    "        \n",
    "        return enc_hid\n",
    "    \n",
    "        \n",
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(self, hidden_size,  device):\n",
    "        super(LSTMDecoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        \n",
    "        self.LSTM = nn.LSTM(hidden_size, hidden_size, batch_first=True).to(self.device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        _, dec_hid = self.LSTM(x)\n",
    "     \n",
    "        return dec_hid\n",
    "        \n",
    "        # prediction을 다시 input으로 decoder 투입\n",
    "        # prediction이 input으로 들어가서 다시 attention한 후에 next prediction을 출력\n",
    "        # attention 후에 decoder 내부에서 기존의 attention처럼 진행하는 것이 가능한가?\n",
    "        # prediction의 hidden_state를 이용해서 next prediction을 하는 것이 예측에 도움을 줄 수 있는가? \n",
    "        \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, sequence_length, device):\n",
    "        super(Attention, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.device = device \n",
    "        self.encoder = LSTMEncoder(input_size, hidden_size, device).to(self.device)\n",
    "        self.decoder = LSTMDecoder(hidden_size, hidden_size, device).to(self.device)\n",
    "        \n",
    "        self.to_query = nn.Linear(hidden_size, hidden_size).to(self.device)\n",
    "        self.to_key = nn.Linear(hidden_size, hidden_size).to(self.device)\n",
    "        self.to_value = nn.Linear(hidden_size, hidden_size).to(self.device)\n",
    "        \n",
    "        \n",
    "        self.LSTM = nn.LSTM(hidden_size, output_size, batch_first = True).to(self.device)\n",
    "        self.fc = nn.Linear(input_size, hidden_size)\n",
    "        self.fc0 = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        # hidden * 2 >> Concatenated hidden, hidden >> original hidden\n",
    "        self.fc1 = nn.Linear(sequence_length * hidden_size, output_size)    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # enc_x, dec_x로 나누기\n",
    "        enc_x, dec_x = x[:int(len(x)*0.5)], x[int(len(x)*0.5):] \n",
    "        \n",
    "        _, enc_hid = self.encoder(enc_x)\n",
    "        \n",
    "        \n",
    "        enc_hid = torch.tensor(enc_hid)\n",
    "        \n",
    "        \n",
    "        dec_input = self.fc(dec_x)\n",
    "        # 36, 10, 16\n",
    "        \n",
    "        for _ in range(sequence_length):\n",
    "            \n",
    "            _, dec_hid = self.decoder(dec_input)\n",
    "            \n",
    "            query = self.to_query(dec_hid) # 1, batch, hidden_size   \n",
    "            key = self.to_key(enc_hid)  # 1, batch, hidden_size\n",
    "            value = self.to_value(enc_hid) # 1, batch, hidden_size\n",
    "            \n",
    "            query = query.permute(1, 2, 0).contiguous() # batch, hidden_size, 1\n",
    "            key = key.permute(1, 0, 2).contiguous() # batch, 1, hidden_size\n",
    "            value = value.permute(1, 2, 0).contiguous() # batch, hidden_size, 1\n",
    "            \n",
    "            \n",
    "            attention_score = query @ key # batch, hidden_size, 1 @ batch, 1, hidden_size\n",
    "            attention_score = attention_score.softmax(dim = -1) # batch, hidden_size, hidden_size\n",
    "\n",
    "            attention_value = attention_score @ value # batch, hidden_size, 1\n",
    "            # hidden_size, hidden_size @ hidden_size, 1 >> hidden_size,1\n",
    "            attention_value = attention_value.permute(2, 0, 1).contiguous() # 1, batch, hidden_size\n",
    "            \n",
    "            new_hidden = torch.tanh(self.fc0(torch.cat((attention_value, dec_hid),dim=2))) # 1, batch, hidden_size\n",
    "            cell_state = torch.zeros_like(new_hidden)\n",
    "            \n",
    "            out, _  = self.LSTM(dec_input, (new_hidden, cell_state)) # batch, sequence_length, hidden_size\n",
    "            out = out.reshape(out.shape[0], -1) # batch, sequence_length * hidden_size\n",
    "            out = self.fc1(out) # batch, 1\n",
    "            \n",
    "            # dec_input = out.unsqueeze(1) # batch, 1, 1\n",
    "            # dec_input = dec_input.repeat(1, hidden_size, 1) # batch, hidden_size, 1\n",
    "            # dec_input = dec_input.\n",
    "            # dec_input = dec_input.permute(2, 0, 1).contiguous() # 1, batch, hidden_size\n",
    "            \n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AML2\\AppData\\Local\\Temp\\ipykernel_8360\\1730110512.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  enc_hid = torch.tensor(enc_hid)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0] loss : 66.2569\n",
      "[epoch: 20] loss : 92.6599\n",
      "[epoch: 40] loss : 92.6599\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #gpu 활성화 확인\n",
    "model = Attention(input_size, hidden_size, output_size, sequence_length, device).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-3)\n",
    "\n",
    "loss_graph = []\n",
    "n = len(train_DL)\n",
    "\n",
    "for epoch in range(100):\n",
    "    running_loss = 0\n",
    "    for data in train_DL:\n",
    "        seq, target = data[0].to(device), data[1].to(device)\n",
    "        target = target[int(len(target)*0.5):] \n",
    "        \n",
    "        \n",
    "        out = model(seq)\n",
    "        loss = criterion(out, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    loss_graph.append(running_loss/n)\n",
    "    if epoch % 20 == 0:\n",
    "        print(\"[epoch: %d] loss : %.4f\" %(epoch,running_loss/n))\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
